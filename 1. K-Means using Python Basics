      '''
      The implementation function should have the signature:

      cluster_kmeans(df, k)
      where

      df is a Pandas dataframe of m observations with n attributes; m rows with n columns (excluding index;
      the index will contain the label for each observation and is not considered an attribute)

      k is the number of clusters to find
      
      The function should return a new dataframe with a single column: the cluster label for each observation. 
      (Copy the index from the input dataframe into the output dataframe to keep them consistent.). 
      It should also return the last Sum-of-the-Square-Errors (SSE) from the clustering.
      '''


import pandas as pd
import numpy as np
import seaborn as sb
import matplotlib.pyplot as plt

from copy import deepcopy

def cluster_kmeans(df, k):
    """
    Clusters the m observations of n attributes 
    in the Pandas' dataframe df into k clusters.
    
    Euclidean distance is used as the proximity metric.
    
    Arguments:
        df   pandas dataframe of m rows with n columns (excluding index)
        k    the number of clusters to search for
        
    Returns:
        a m x 1 dataframe of cluster labels for each of the m observations
        retaining the original dataframe's (df's) index
        
        the final Sum-of-Error-Squared (SSE) from the clustering
    """
    # Replace pass with your solution.
    
    #Distance calculation
    def dist(a, b, ax = 1):
        return np.linalg.norm(a-b, axis = ax)
    
    data = df
    #Scaling data 
    #data -= data.min()
    #data /= data.max()/10
    
    X = data.astype(float).values.tolist()
    X = np.array(X)
    
    final_SSE = np.sum(X**2) 
    count = 0
    
    #we will perform K-means for 10 times.
    for i in range(10):
        
        number_of_rows = X.shape[0]
        random_indices = np.random.choice(number_of_rows, size=k, replace=False)
        C = X[random_indices, :]


        # To save new value of centroids when it changes
        C_old = np.zeros(C.shape)
        # Cluster Lable names (0, 1, 2, etc)
        clusters = np.zeros(len(X),dtype=np.int64)
        # Error func. - Distance between new centroids and old centroids
        error = dist(C, C_old, None)

        # Loop will run till the error becomes zero
        while np.all(error) > 0.5:
            count = count + 1
            # Assigning each value to its nearest cluster
            for i in range(len(X)):
                distances = dist(X[i], C)
                cluster = np.argmin(distances)
                clusters[i] = cluster
            # Storing the old centroid values
            C_old = deepcopy(C)
            # Finding the new centroids by taking the average value
            for i in range(k):
                points = [X[j] for j in range(len(X)) if clusters[j] == i]
                C[i] = np.mean(points, axis=0)
            error = dist(C, C_old, None)

        #Calculate SSE for final C value        
        sse_list = list()
        for i in range(len(X)):
            distances = dist(X[i], C)
            sse_list.append(distances)
        min_dist = np.amin(sse_list, axis=1)
        sq_min_dist = min_dist ** 2
        SSE = np.sum(sq_min_dist)
        
        if SSE < final_SSE:
            final_SSE = SSE
            C_Final = C
            final_clusters = clusters
        
        
    
    final_df = pd.DataFrame(final_clusters, columns=['Cluster Label'])
    final_df.index = df.index
    #print(count)  #You can use count to check how many times has your loop been executed.
    return final_df,final_SSE


# Call the function cluster_kmeans(df, k) with df as your numerical data frame and k as number of clusters you want
# Creating some data to check
test_df = pd.DataFrame()
arr1 = np.array([9000, 7500, 800, 1500])
arr2 = np.array([150, 80, 10000, 5000])
arr3 = np.array([3500, 2500, 5000, 2800])

mat = np.array([arr1,arr2,arr3])

for i in range(0, 50):
    r_int = np.random.randint(-50, 50)
    idx = i%3
    val = np.add(mat[idx], np.array([r_int]))
    test_df = test_df.append(pd.Series(val), ignore_index = True)

test_df = test_df.iloc[np.random.permutation(len(test_df))]
test_df.reset_index(inplace=True)
test_df = test_df.drop(['index'], axis = 1)
test_df.head()

df1,result = cluster_kmeans(test_df,3)
